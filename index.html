<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
<title>Mobile HUD — 3D-ish Icons Demo (Person / Car)</title>
<style>
  :root{--bg:#07121a;--panel:rgba(255,255,255,0.04);--accent:#1ea7ff}
  html,body{height:100%;margin:0;font-family:Inter,system-ui,Segoe UI,Roboto,Arial;background:var(--bg);color:#eaf4fb}
  .wrap{max-width:900px;margin:14px auto;padding:12px}
  header{display:flex;align-items:center;justify-content:space-between;gap:12px}
  h1{font-size:18px;margin:0}
  .controls{display:flex;gap:8px;align-items:center;margin:10px 0;flex-wrap:wrap}
  button,select,input[type=range]{background:var(--accent);border:none;color:#012;padding:8px 12px;border-radius:10px;font-weight:700;cursor:pointer}
  button.secondary{background:#384764}
  #stack{position:relative;border-radius:12px;overflow:hidden;background:#000;box-shadow:0 8px 30px rgba(0,0,0,.6)}
  video#cam{display:block;width:100%;height:auto}
  canvas#overlay{position:absolute;left:0;top:0;pointer-events:none;width:100%;height:100%}
  .panel{background:var(--panel);padding:10px;border-radius:10px;border:1px solid rgba(255,255,255,.06)}
  .status{margin-top:8px;padding:8px;border-radius:8px;background:rgba(255,255,255,0.02);color:#cde3ff;font-weight:700}
  label.small{font-size:13px;opacity:.9}
  footer{margin-top:12px;text-align:center;color:#9fb6c9;font-size:13px}
  @media(max-width:640px){ .wrap{padding:8px} }
</style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>Mobile HUD — 3D-ish Icon Detector</h1>
        <div class="small">Detects people & cars and draws stylized 3D icons above them. Use Test Mode if camera permission is unavailable.</div>
      </div>
      <div>
        <label class="small">Confidence: <span id="confVal">0.55</span></label><br>
        <input id="conf" type="range" min="0.2" max="0.95" step="0.05" value="0.55" style="vertical-align:middle">
      </div>
    </header>

    <div class="controls">
      <button id="startBtn">Start</button>
      <button id="stopBtn" class="secondary">Stop</button>
      <label style="display:flex;align-items:center;gap:6px">
        <input id="testMode" type="checkbox" /> Test Mode (use reference image)
      </label>
      <select id="camSelect" style="padding:8px;border-radius:8px;background:#0f1322;color:#cde3ff;border:1px solid rgba(255,255,255,.08)"></select>
      <div style="margin-left:auto" id="status">Status: idle</div>
    </div>

    <div id="stack" style="aspect-ratio:16/9" class="panel">
      <video id="cam" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>

    <div class="status" id="desc">No detections yet.</div>

    <footer>Model runs locally in the browser (TensorFlow.js). No video leaves your device.</footer>
  </div>

  <!-- TensorFlow and COCO-SSD (mobile) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3"></script>

  <script>
    // Test image path (your uploaded file) — used in Test Mode
    const TEST_IMAGE_URL = '/mnt/data/IMG_285CA3AF-DA1D-48E0-B31B-0C2E8A3B72EC.jpeg';

    // DOM
    const cam = document.getElementById('cam');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d', { willReadFrequently: true });
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');
    const testMode  = document.getElementById('testMode');
    const camSelect = document.getElementById('camSelect');
    const conf = document.getElementById('conf');
    const confVal = document.getElementById('confVal');
    const statusEl = document.getElementById('status');
    const desc = document.getElementById('desc');

    // State
    let model = null;
    let stream = null;
    let running = false;
    let raf = null;
    let devices = [];
    let currentDeviceId = null;
    const DETECT_INTERVAL_FRAMES = 3; // run detection every N frames (reduce CPU)
    let frameCounter = 0;
    let lastDetections = [];

    conf.oninput = ()=> confVal.textContent = parseFloat(conf.value).toFixed(2);

    function setStatus(t){ statusEl.textContent = t; }
    function setDesc(t){ desc.textContent = t; }

    async function listCameras(){
      try{
        const devs = await navigator.mediaDevices.enumerateDevices();
        const vids = devs.filter(d=>d.kind==='videoinput');
        devices = vids;
        camSelect.innerHTML = vids.map((v,i)=>`<option value="${v.deviceId}">${v.label || 'Camera '+(i+1)}</option>`).join('');
        if(vids[0]) currentDeviceId = vids[0].deviceId;
      }catch(e){ console.warn('enumerateDevices failed', e); }
    }

    async function startCamera(deviceId=null){
      try{
        if(location.protocol !== 'https:' && location.hostname !== 'localhost'){
          setStatus('Using Test Mode or open via HTTPS for camera.');
        }
        const constraints = deviceId ? { video: { deviceId:{ exact: deviceId }, width:{ideal:1280}, height:{ideal:720} } } :
                                       { video: { facingMode:'environment', width:{ideal:1280}, height:{ideal:720} } };
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        cam.srcObject = stream;
        await cam.play();
        await listCameras();
        fitOverlay();
        setStatus('Camera ready');
      }catch(e){
        console.error('startCamera', e);
        setStatus('Camera error: ' + (e.message||e));
        throw e;
      }
    }

    function stopCamera(){
      if(stream){ stream.getTracks().forEach(t=>t.stop()); stream = null; }
      if(raf) cancelAnimationFrame(raf);
      running = false;
      setStatus('Stopped');
    }

    function fitOverlay(){
      overlay.width = cam.clientWidth;
      overlay.height = cam.clientHeight;
      overlay.style.width = cam.clientWidth + 'px';
      overlay.style.height = cam.clientHeight + 'px';
    }
    window.addEventListener('resize', ()=>{ if(cam.srcObject) fitOverlay(); });

    // Load model (COCO-SSD)
    async function loadModel(){
      if(model) return model;
      setStatus('Loading model...');
      model = await cocoSsd.load({ base: 'mobilenet_v2' });
      setStatus('Model ready');
      return model;
    }

    // draw stylized 3D-like car icon (rounded body + top highlight + shadow)
    function drawCarIcon(cx, cy, w, h, label){
      const g = ctx.createLinearGradient(cx - w/2, cy - h, cx + w/2, cy + h);
      g.addColorStop(0, '#e8eef3');
      g.addColorStop(1, '#d0d6db');
      // shadow
      ctx.beginPath();
      ctx.ellipse(cx, cy + h*0.36, w*0.6, h*0.2, 0, 0, Math.PI*2);
      ctx.fillStyle = 'rgba(0,0,0,0.22)'; ctx.fill();

      // body (rounded)
      roundRect(ctx, cx - w/2, cy - h/2, w, h, Math.min(w,h)*0.12, true, false, g);
      // roof/top highlight
      ctx.beginPath();
      ctx.fillStyle = 'rgba(255,255,255,0.85)';
      ctx.ellipse(cx, cy - h*0.18, w*0.36, h*0.18, 0, 0, Math.PI*2);
      ctx.fill();

      // windows (dark)
      ctx.fillStyle = 'rgba(20,26,30,0.95)';
      ctx.fillRect(cx - w*0.22, cy - h*0.12, w*0.44, h*0.2);

      // label
      if(label){
        ctx.font = `${Math.round(Math.max(12, w*0.12))}px sans-serif`;
        ctx.fillStyle = '#000';
        ctx.fillText(label, cx - ctx.measureText(label).width/2, cy + h/2 + 18);
      }
    }

    // draw stylized 3D-like person icon (simple silhouette with shading)
    function drawPersonIcon(cx, cy, size, label){
      const w = size*0.6, h = size;
      // shadow
      ctx.beginPath();
      ctx.ellipse(cx, cy + h*0.5, w*0.9, h*0.28, 0, 0, Math.PI*2); ctx.fillStyle = 'rgba(0,0,0,0.22)'; ctx.fill();

      // body
      ctx.save();
      ctx.beginPath();
      ctx.fillStyle = '#2a6f9e';
      // torso
      ctx.roundRect = ctx.roundRect || function(x,y,w,h,r){ this.beginPath(); this.moveTo(x+r,y); this.arcTo(x+w,y,x+w,y+h,r); this.arcTo(x+w,y+h,x,y+h,r); this.arcTo(x,y+h,x,y,r); this.arcTo(x,y,x+w,y,r); this.closePath(); };
      ctx.roundRect(cx - w/2, cy - h*0.2, w, h*0.6, 8);
      ctx.fill();

      // head
      ctx.beginPath();
      ctx.fillStyle = '#f1d1b5';
      ctx.arc(cx, cy - h*0.35, size*0.17, 0, Math.PI*2);
      ctx.fill();

      // light top highlight
      ctx.beginPath();
      ctx.fillStyle = 'rgba(255,255,255,0.12)';
      ctx.ellipse(cx - w*0.15, cy - h*0.1, w*0.22, h*0.28, -0.2, 0, Math.PI*2);
      ctx.fill();

      ctx.restore();

      if(label){
        ctx.font = `${Math.round(Math.max(12, size*0.12))}px sans-serif`;
        ctx.fillStyle = '#000';
        ctx.fillText(label, cx - ctx.measureText(label).width/2, cy + h*0.62);
      }
    }

    // helper rounded rect that can use gradient fill
    function roundRect(ctx, x, y, w, h, r, fill, stroke, fillStyle){
      if(r===undefined) r=8;
      ctx.beginPath();
      ctx.moveTo(x+r, y);
      ctx.arcTo(x+w, y, x+w, y+h, r);
      ctx.arcTo(x+w, y+h, x, y+h, r);
      ctx.arcTo(x, y+h, x, y, r);
      ctx.arcTo(x, y, x+w, y, r);
      ctx.closePath();
      if(fill){
        if(fillStyle) ctx.fillStyle = fillStyle;
        ctx.fill();
      }
      if(stroke) ctx.stroke();
    }

    // map COCO class names to our icon types
    const ICON_MAP = {
      'person':'person',
      'car':'car','truck':'car','bus':'car','motorcycle':'car','bicycle':'car'
    };

    // draw loop: draw icons & debug boxes
    function drawDetections(dets, srcW, srcH){
      // overlay size
      const ow = overlay.width, oh = overlay.height;
      ctx.clearRect(0,0,ow,oh);

      // scale from model coords to overlay coords
      const sx = ow / srcW, sy = oh / srcH;

      for(const d of dets){
        const cls = d.class;
        const score = d.score;
        const [x,y,w,h] = d.bbox; // model bbox format [x,y,width,height]
        const cx = (x + w/2) * sx;
        const cy = (y + h/2) * sy;
        const sw = w * sx;
        const sh = h * sy;

        const iconType = ICON_MAP[cls] || null;
        const label = `${cls} ${(score*100).toFixed(0)}%`;

        // draw 3D-ish icons sized relative to bbox
        if(iconType === 'car'){
          drawCarIcon(cx, cy - sh*0.08, Math.max(60, sw*0.85), Math.max(28, sh*0.45), cls);
        } else if(iconType === 'person'){
          drawPersonIcon(cx, cy, Math.max(48, Math.min(sh*1.0, sw*1.1)), cls);
        }

        // optional small debug bbox (semi-transparent)
        ctx.strokeStyle = 'rgba(30,120,255,0.45)';
        ctx.lineWidth = 2;
        ctx.strokeRect(x*sx, y*sy, sw, sh);
      }
    }

    // run detection on an image/canvas
    async function detectOnCanvas(sourceCanvas){
      if(!model) return [];
      const threshold = parseFloat(conf.value);
      const predictions = await model.detect(sourceCanvas);
      // filter and map to uniform objects
      const keep = predictions.filter(p => (p.score||0) >= threshold);
      return keep.map(p => ({
        class: p.class,
        score: p.score,
        bbox: p.bbox // [x,y,w,h] (pixels in source canvas)
      }));
    }

    // temporary canvas used to scale frames before detection (improve perf)
    function createTempCanvas(w,h){
      const c = document.createElement('canvas');
      c.width = w; c.height = h;
      return c;
    }

    // main loop
    async function loop(){
      if(!running) return;
      frameCounter++;
      try{
        // prepare a small canvas frame for detection (scaling reduces CPU)
        const imgScale = 0.6; // 0.3-0.8 recommended for phones
        let srcCanvas = document.createElement('canvas');
        const vw = cam.videoWidth || cam.clientWidth;
        const vh = cam.videoHeight || cam.clientHeight;
        if(testMode.checked){
          // load reference image
          const img = new Image();
          img.src = TEST_IMAGE_URL;
          await img.decode();
          const scale = Math.min(1, 640 / img.naturalWidth);
          srcCanvas.width = Math.floor(img.naturalWidth * scale * imgScale);
          srcCanvas.height = Math.floor(img.naturalHeight * scale * imgScale);
          const tctx = srcCanvas.getContext('2d');
          tctx.drawImage(img, 0, 0, srcCanvas.width, srcCanvas.height);
        } else {
          if(!stream){ raf = requestAnimationFrame(loop); return; }
          srcCanvas.width = Math.max(160, Math.floor(vw * imgScale));
          srcCanvas.height = Math.max(120, Math.floor(vh * imgScale));
          const tctx = srcCanvas.getContext('2d');
          tctx.drawImage(cam, 0, 0, srcCanvas.width, srcCanvas.height);
        }

        // run detection only every N frames
        let dets = lastDetections;
        if(frameCounter % DETECT_INTERVAL_FRAMES === 0){
          const raw = await detectOnCanvas(srcCanvas);
          // convert bbox coords in scaled canvas back to original camera resolution for mapping
          // model returns [x,y,w,h] in srcCanvas pixels
          // get actual source dims (used later to scale overlay)
          lastDetections = raw;
          dets = raw;
        }

        // draw on overlay, scale up using srcCanvas size mapping
        // overlay uses live cam size (or test image displayed size)
        // need src dims:
        const srcW = srcCanvas.width, srcH = srcCanvas.height;
        // resize overlay to video display size
        overlay.width = cam.clientWidth || srcW;
        overlay.height = cam.clientHeight || srcH;
        drawDetections(dets, srcW, srcH);

        if(dets.length){
          setDesc('Detected: ' + dets.map(d => d.class).join(', '));
        } else {
          setDesc('No side objects detected.');
        }
      }catch(e){
        console.error('loop error', e);
      } finally {
        raf = requestAnimationFrame(loop);
      }
    }

    // UI wiring
    startBtn.onclick = async ()=>{
      try{
        await loadModel();
        if(!testMode.checked){
          await listCameras();
          await startCamera(currentDeviceId);
        } else {
          // when test mode, set a nice display size from the image
          const img = new Image();
          img.src = TEST_IMAGE_URL;
          await img.decode();
          // show the image in the video area by drawing into a temporary blob -> set as video poster fallback
          const tmp = document.createElement('canvas');
          const scale = Math.min(1, 960 / img.naturalWidth);
          tmp.width = Math.round(img.naturalWidth * scale);
          tmp.height = Math.round(img.naturalHeight * scale);
          const tctx = tmp.getContext('2d'); tctx.drawImage(img,0,0,tmp.width,tmp.height);
          cam.style.display = 'none';
          overlay.width = tmp.width; overlay.height = tmp.height;
          overlay.style.width = tmp.width + 'px'; overlay.style.height = tmp.height + 'px';
          const imgData = tmp.toDataURL();
          // show the image behind overlay by setting stack background
          document.getElementById('stack').style.background = `url(${imgData}) center/cover no-repeat`;
        }
        running = true;
        frameCounter = 0;
        raf = requestAnimationFrame(loop);
        setStatus('Running');
      }catch(e){
        console.error(e);
        setStatus('Start failed: ' + (e.message||e));
      }
    };

    stopBtn.onclick = ()=>{
      stopCamera();
      // reset background if test mode
      document.getElementById('stack').style.background = null;
      cam.style.display = '';
      overlay.width = overlay.clientWidth;
      overlay.height = overlay.clientHeight;
      ctx.clearRect(0,0,overlay.width,overlay.height);
      setDesc('Stopped.');
    };

    camSelect.onchange = async (e)=>{
      currentDeviceId = e.target.value;
      if(stream){ stopCamera(); await startCamera(currentDeviceId); }
    };

    // initial setup
    (async function init(){
      try{ await tf.ready(); console.log('TF backend:', tf.getBackend()); }catch(e){ console.warn('tf.ready failed', e); }
      await listCameras().catch(()=>{});
      // preload model in background
      loadModel().catch(e=>console.warn('model preload failed', e));
      setDesc('Ready. Use Test Mode if camera not available or open via HTTPS to allow camera.');
    })();
  </script>
</body>
</html>