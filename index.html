<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Live Side Detector — 3D-style HUD (Camera Ready)</title>
<style>
  :root{
    --bg:#0b1116; --card:rgba(255,255,255,0.04); --accent:#18a0ff; --muted:#9fb6c9;
  }
  *{box-sizing:border-box}
  html,body{height:100%;margin:0;font-family:Inter,system-ui,Segoe UI,Roboto,Arial;background:var(--bg);color:#eaf4fb}
  .wrap{max-width:1100px;margin:12px auto;padding:14px}
  header{display:flex;align-items:center;justify-content:space-between;gap:12px}
  h1{font-size:18px;margin:0}
  .controls{display:flex;gap:8px;flex-wrap:wrap;align-items:center;margin:12px 0}
  button,select,input[type=range]{background:var(--accent);border:none;color:#012;padding:8px 12px;border-radius:10px;font-weight:700;cursor:pointer}
  button.secondary{background:#384764}
  .panel{background:var(--card);padding:12px;border-radius:14px;border:1px solid rgba(255,255,255,0.06);backdrop-filter:blur(6px)}
  .two{display:flex;gap:12px;flex-wrap:wrap}
  .left{flex:1 1 520px;min-width:260px}
  .right{flex:0 1 320px;min-width:220px}
  .stack{position:relative;border-radius:12px;overflow:hidden;background:#000;aspect-ratio:16/9}
  video#cam{display:block;width:100%;height:100%;object-fit:cover}
  canvas.overlay{position:absolute;left:0;top:0;pointer-events:none}
  .status{margin-top:8px;padding:10px;border-radius:8px;background:rgba(255,255,255,0.02);font-weight:700;color:#cde3ff}
  .small{font-size:13px;color:var(--muted)}
  label{display:flex;gap:8px;align-items:center}
  input[type=checkbox]{transform:scale(1.05)}
  footer{margin-top:12px;text-align:center;color:var(--muted);font-size:13px}
  .hint{margin-top:8px;color:#ffd36b;display:none}
  .controls .right{margin-left:auto}
  .controls .right .conf{display:flex;align-items:center;gap:8px}
  .debug{margin-top:8px;padding:8px;background:rgba(255,255,255,0.02);border-radius:8px;color:var(--muted);font-family:monospace;font-size:13px;max-height:120px;overflow:auto}
  @media(max-width:640px){ .two{flex-direction:column} }
</style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>Live Side Detector — 3D-style HUD</h1>
        <div class="small">Phone acts as the car. Press <b>Start</b> to allow camera and start live detection.</div>
      </div>
      <div class="right small conf">
        <div>Confidence: <span id="confVal">0.55</span></div>
        <input id="conf" type="range" min="0.2" max="0.95" step="0.05" value="0.55">
      </div>
    </header>

    <div class="controls">
      <button id="startBtn">Start (Request Camera)</button>
      <button id="stopBtn" class="secondary">Stop</button>
      <label><input id="testMode" type="checkbox" checked> Test mode (use reference image)</label>
      <select id="camSelect" title="Camera" style="padding:8px;border-radius:8px;background:#0f1322;color:#cde3ff;border:1px solid rgba(255,255,255,.06)"></select>
      <div style="margin-left:auto" id="status">Status: idle</div>
    </div>

    <div class="panel two">
      <div class="left">
        <div class="stack" id="stack">
          <video id="cam" autoplay playsinline muted></video>
          <canvas id="boxes" class="overlay"></canvas>
          <canvas id="hud" class="overlay"></canvas>
        </div>

        <div class="status" id="desc">No side objects detected.</div>
        <div class="hint" id="hint">⚠️ Camera requires HTTPS (GitHub Pages) or open on localhost to run on phone. Allow camera permission when prompted.</div>
        <div class="debug" id="dbg">Debug log...</div>
      </div>

      <div class="right">
        <div style="display:flex;gap:8px;flex-wrap:wrap;margin-bottom:10px">
          <button id="showLeft" class="secondary">Show Left (debug)</button>
          <button id="showRight" class="secondary">Show Right (debug)</button>
          <button id="showBoth" class="secondary">Show Both (debug)</button>
          <button id="clear" class="secondary">Clear</button>
        </div>

        <div style="font-size:13px;background:rgba(255,255,255,0.02);padding:10px;border-radius:8px">
          <div><b>Test image (local):</b></div>
          <div style="font-size:12px;opacity:.9;margin-top:6px">Using this reference image for Test Mode (provided file):</div>
          <div style="margin-top:6px;font-family:monospace;background:#08101a;padding:8px;border-radius:6px;color:#9fb6c9">/mnt/data/C11C7C56-B110-433A-ACEC-8C2DDC0B4561.jpeg</div>
          <div style="font-size:13px;margin-top:8px">Open page via HTTPS or localhost to enable camera on phone.</div>
        </div>
      </div>
    </div>

    <footer>All detection runs locally (TensorFlow.js coco-ssd). No video leaves your device.</footer>
  </div>

  <!-- TFJS + COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3"></script>

<script>
/* Full single-file app:
   - Live camera detection using coco-ssd (fast MobileNet)
   - Test mode uses local file path (change TEST_IMAGE_PATH if needed)
   - Draws top-down 3D-like HUD (car in center, side bubbles)
   - Robust camera permission handling and device selector
*/

const TEST_IMAGE_PATH = '/mnt/data/C11C7C56-B110-433A-ACEC-8C2DDC0B4561.jpeg'; // local image you uploaded

// DOM
const cam = document.getElementById('cam');
const boxesCanvas = document.getElementById('boxes');
const hudCanvas = document.getElementById('hud');
const ctxBoxes = boxesCanvas.getContext('2d', { willReadFrequently: true });
const ctxHUD = hudCanvas.getContext('2d', { willReadFrequently: true });

const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const testMode  = document.getElementById('testMode');
const camSelect = document.getElementById('camSelect');
const conf      = document.getElementById('conf');
const confVal   = document.getElementById('confVal');
const desc      = document.getElementById('desc');
const hint      = document.getElementById('hint');
const statusEl  = document.getElementById('status');
const dbg = document.getElementById('dbg');

const showLeft = document.getElementById('showLeft');
const showRight = document.getElementById('showRight');
const showBoth = document.getElementById('showBoth');
const clearBtn = document.getElementById('clear');

let model = null;
let stream = null;
let running = false;
let raf = null;
let devices = [];
let currentDeviceId = null;
let lastFrameTime = 0;
let throttleMs = 100; // ~10 FPS for phones; lower for faster detection but heavier

function log(...args){ dbg.textContent += '\\n' + args.join(' '); dbg.scrollTop = dbg.scrollHeight; console.log(...args); }
function setStatus(t){ statusEl.textContent = t; }
function setDesc(t){ desc.textContent = t; }

// fit canvases to stack element
function fitCanvases(){
  const rect = document.getElementById('stack').getBoundingClientRect();
  [boxesCanvas, hudCanvas].forEach(c=>{
    c.width = Math.floor(rect.width);
    c.height = Math.floor(rect.height);
    c.style.left = '0px';
    c.style.top = '0px';
    c.style.width = rect.width + 'px';
    c.style.height = rect.height + 'px';
  });
  drawHUD(false,false,[],[]);
}
window.addEventListener('resize', fitCanvases);
window.addEventListener('orientationchange', ()=>setTimeout(fitCanvases,200));
fitCanvases();

// load model
async function loadModel(){
  if(model) return model;
  setStatus('Loading model...');
  try{
    model = await cocoSsd.load({ base: 'mobilenet_v2' });
    setStatus('Model ready');
    log('COCO-SSD loaded');
    return model;
  }catch(e){
    setStatus('Model load failed: ' + (e.message || e));
    log('Model load error', e);
    throw e;
  }
}

// list cameras
async function listCameras(){
  try{
    const devs = await navigator.mediaDevices.enumerateDevices();
    devices = devs.filter(d=>d.kind === 'videoinput');
    camSelect.innerHTML = devices.map((d,i)=>`<option value="${d.deviceId}">${d.label || 'Camera '+(i+1)}</option>`).join('');
    if(devices.length && !currentDeviceId) currentDeviceId = devices[0].deviceId;
    log('Cameras:', devices.map(d=>d.label || d.deviceId).join('; '));
  }catch(e){ log('enumerateDevices failed', e); }
}

// start camera
async function startCamera(deviceId=null){
  try{
    // show hint if not secure context
    if(location.protocol !== 'https:' && location.hostname !== 'localhost'){
      hint.style.display = 'block';
      hint.textContent = '⚠️ Camera requires HTTPS (GitHub Pages) or open on localhost to run on phone.';
    } else {
      hint.style.display = 'none';
    }

    const constraints = deviceId ? { video: { deviceId: { exact: deviceId }, width:{ideal:1280}, height:{ideal:720} } }
                                 : { video: { facingMode: 'environment', width:{ideal:1280}, height:{ideal:720} } };

    stream = await navigator.mediaDevices.getUserMedia(constraints);
    cam.srcObject = stream;
    await cam.play();
    await listCameras();
    setStatus('Camera ready');
    fitCanvases();
    log('Camera started', cam.videoWidth + 'x' + cam.videoHeight);
  }catch(e){
    setStatus('Camera error: ' + (e.message || e));
    log('startCamera error', e);
    hint.style.display = 'block';
    if(e.name === 'NotAllowedError') hint.textContent = 'Please allow camera permission in the browser address bar.';
    else if(e.name === 'NotFoundError') hint.textContent = 'No camera found.';
    else hint.textContent = e.message || String(e);
    throw e;
  }
}

// stop camera
function stopCamera(){
  if(stream){
    stream.getTracks().forEach(t=>t.stop());
    stream = null;
  }
  if(raf) cancelAnimationFrame(raf);
  running = false;
  setStatus('Stopped');
  log('Camera stopped');
}

// draw HUD (3D-style top-down)
function drawHUD(left=false,right=false,leftTypes=[],rightTypes=[]){
  const W = hudCanvas.width, H = hudCanvas.height;
  ctxHUD.clearRect(0,0,W,H);
  // background card
  ctxHUD.fillStyle = '#f3f6f9';
  ctxHUD.fillRect(0,0,W,H);

  const cx = W/2, cy = H*0.72;

  // soft road shapes (three ellipses)
  ctxHUD.fillStyle = 'rgba(220,220,225,0.96)';
  ctxHUD.beginPath();
  ctxHUD.ellipse(cx - W*0.35, cy-40, W*0.24, H*0.34, 0, 0, Math.PI*2);
  ctxHUD.ellipse(cx + W*0.35, cy-40, W*0.24, H*0.34, 0, 0, Math.PI*2);
  ctxHUD.ellipse(cx, cy - 80, W*0.22, H*0.38, 0, 0, Math.PI*2);
  ctxHUD.fill();

  // car shape (simple rounded rectangle with inner dark cabin)
  const carW = W*0.22, carH = H*0.26;
  ctxHUD.save();
  ctxHUD.translate(cx, cy - 40);
  ctxHUD.shadowColor = 'rgba(0,0,0,0.18)';
  ctxHUD.shadowBlur = 18;
  ctxHUD.shadowOffsetY = 8;
  roundRect(ctxHUD, -carW/2, -carH/2, carW, carH, 18, true, false, '#ffffff');
  roundRect(ctxHUD, -carW*0.33, -carH*0.33, carW*0.66, carH*0.66, 10, true, false, '#10141a');
  ctxHUD.restore();

  if(left) drawSideBubble('left', leftTypes[0] || 'Side Object');
  if(right) drawSideBubble('right', rightTypes[0] || 'Side Object');
}

function roundRect(c,x,y,w,h,r,fill,stroke,fillColor){
  if(r===undefined) r=6;
  c.beginPath();
  c.moveTo(x+r,y);
  c.arcTo(x+w,y,x+w,y+h,r);
  c.arcTo(x+w,y+h,x,y+h,r);
  c.arcTo(x,y+h,x,y,r);
  c.arcTo(x,y,x+w,y,r);
  c.closePath();
  if(fill){ c.fillStyle = fillColor || '#fff'; c.fill(); }
  if(stroke){ c.stroke(); }
}

function drawSideBubble(side,label){
  const W = hudCanvas.width, H = hudCanvas.height;
  const cx = W/2, cy = H*0.72;
  const sideX = (side === 'left') ? cx - W*0.35 : cx + W*0.35;
  const py = cy - 40 - H*0.06;
  const color = (side === 'left') ? 'rgba(120,240,160,0.96)' : 'rgba(255,195,70,0.95)';
  const rad = Math.min(W,H) * 0.22;
  const g = ctxHUD.createRadialGradient(sideX, py, rad*0.05, sideX, py, rad);
  g.addColorStop(0, color.replace(/\)$/,'1)'));
  g.addColorStop(1, color.replace(/\)$/,'0)'));
  ctxHUD.fillStyle = g;
  ctxHUD.beginPath(); ctxHUD.arc(sideX, py, rad, 0, Math.PI*2); ctxHUD.fill();

  ctxHUD.strokeStyle = 'rgba(255,255,255,0.06)'; ctxHUD.lineWidth = 2;
  ctxHUD.beginPath(); ctxHUD.arc(sideX, py, rad, 0, Math.PI*2); ctxHUD.stroke();

  // label balloon
  ctxHUD.fillStyle = 'rgba(0,0,0,0.65)'; ctxHUD.font = '14px sans-serif';
  const tw = ctxHUD.measureText(label).width;
  const lx = sideX - tw/2 - 10;
  const ly = py - rad - 28;
  roundRect(ctxHUD, lx, ly, tw + 20, 26, 8, true, false, 'rgba(0,0,0,0.65)');
  ctxHUD.fillStyle = '#fff';
  ctxHUD.fillText(label, lx + 10, ly + 18);
}

// draw detection boxes scaled to overlay canvas
function drawBoxes(preds, threshold, srcW, srcH){
  const W = boxesCanvas.width, H = boxesCanvas.height;
  ctxBoxes.clearRect(0,0,W,H);
  ctxBoxes.lineWidth = 2;
  ctxBoxes.font = '12px monospace';
  const scaleX = W / srcW, scaleY = H / srcH;
  for(const p of preds){
    const [x,y,w,h] = p.bbox;
    const sx = x * scaleX, sy = y * scaleY, sw = w * scaleX, sh = h * scaleY;
    ctxBoxes.strokeStyle = p.score >= threshold ? 'rgba(10,120,255,0.95)' : 'rgba(150,150,150,0.45)';
    ctxBoxes.strokeRect(sx, sy, sw, sh);
    const label = `${p.class} ${(p.score*100).toFixed(0)}%`;
    ctxBoxes.fillStyle = 'rgba(0,0,0,0.6)';
    const tw = ctxBoxes.measureText(label).width + 8;
    ctxBoxes.fillRect(sx, Math.max(0, sy - 20), tw, 18);
    ctxBoxes.fillStyle = '#fff';
    ctxBoxes.fillText(label, sx + 4, Math.max(0, sy - 6));
  }
}

// detection loop
async function loop(now){
  if(!running) return;
  if(!model){
    try{ await loadModel(); } catch(e){ setTimeout(()=>raf = requestAnimationFrame(loop), 300); return; }
  }
  if(now - lastFrameTime < throttleMs){ raf = requestAnimationFrame(loop); return; }
  lastFrameTime = now;

  try{
    let preds = [], srcW = 640, srcH = 480;
    if(testMode.checked){
      // detect on the test image (local file)
      const img = new Image();
      img.src = TEST_IMAGE_PATH;
      await img.decode();
      const tmp = document.createElement('canvas');
      const scale = Math.min(1, 640 / img.naturalWidth);
      tmp.width = Math.floor(img.naturalWidth * scale);
      tmp.height = Math.floor(img.naturalHeight * scale);
      tmp.getContext('2d').drawImage(img, 0, 0, tmp.width, tmp.height);
      preds = await model.detect(tmp);
      srcW = tmp.width; srcH = tmp.height;
    } else {
      // live video element
      if(!cam.videoWidth || cam.readyState < 2){
        raf = requestAnimationFrame(loop);
        return;
      }
      preds = await model.detect(cam);
      srcW = cam.videoWidth; srcH = cam.videoHeight;
    }

    const threshold = parseFloat(conf.value);
    confVal.textContent = threshold.toFixed(2);

    // filter relevant classes
    const useful = preds.filter(p => ['person','car','bus','truck','bicycle','motorbike'].includes(p.class) && p.score >= 0.25);

    // determine left / right by bbox center
    let leftFound=false, rightFound=false, leftTypes=[], rightTypes=[];
    for(const p of useful){
      const [x,y,w,h] = p.bbox;
      const cx = x + w/2;
      const nx = cx / srcW;
      if(nx < 0.46){ leftFound = true; leftTypes.push(p.class); }
      else if(nx > 0.54){ rightFound = true; rightTypes.push(p.class); }
      else { leftFound = true; rightFound = true; leftTypes.push(p.class); rightTypes.push(p.class); }
    }

    // draw visuals
    drawHUD(leftFound, rightFound, leftTypes, rightTypes);
    drawBoxes(preds, threshold, srcW, srcH);

    // update text
    if(leftFound || rightFound){
      const parts = [];
      if(leftFound) parts.push('Left: ' + (leftTypes.join(', ') || 'object'));
      if(rightFound) parts.push('Right: ' + (rightTypes.join(', ') || 'object'));
      setDesc('Detected: ' + parts.join(' · '));
      setStatus('Object detected at side');
    } else {
      setDesc('No side objects detected.');
      setStatus('No side objects');
    }

  }catch(e){
    console.error('detection error', e);
    setStatus('Detection error: ' + (e.message || e));
    log('detection error', e);
  } finally {
    raf = requestAnimationFrame(loop);
  }
}

// UI events
startBtn.onclick = async ()=>{
  try{
    await loadModel();
    if(!testMode.checked){
      await listCameras();
      await startCamera(currentDeviceId);
    } else {
      // even in test mode, ensure canvases are sized
      fitCanvases();
    }
    running = true;
    lastFrameTime = performance.now();
    raf = requestAnimationFrame(loop);
    setStatus('Running');
    log('Detection started (testMode=' + testMode.checked + ')');
  }catch(e){
    log('Start failed', e);
  }
};
stopBtn.onclick = ()=>{ stopCamera(); setDesc('No side objects detected.'); };

camSelect.onchange = async (e)=>{
  currentDeviceId = e.target.value;
  if(stream){ stopCamera(); await startCamera(currentDeviceId); }
};

showLeft.onclick = ()=>{ drawHUD(true,false,['person'],[]); setDesc('Detected: Left (debug)'); };
showRight.onclick = ()=>{ drawHUD(false,true,[],['person']); setDesc('Detected: Right (debug)'); };
showBoth.onclick = ()=>{ drawHUD(true,true,['car'],['car']); setDesc('Detected: Both (debug)'); };
clearBtn.onclick = ()=>{ drawHUD(false,false,[],[]); setDesc('No side objects detected.'); };

conf.oninput = ()=> confVal.textContent = parseFloat(conf.value).toFixed(2);

// initialization
(async function init(){
  try{ await tf.ready(); log('TF backend:', tf.getBackend()); }catch(e){ log('tf ready failed', e); }
  await listCameras();
  // preload model in background (non-blocking)
  loadModel().catch(e=>log('preload failed', e));
  fitCanvases();
  drawHUD(false,false,[],[]);
})();
</script>
</body>
</html>