<!doctype html>
<html lang="ar">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Top-Down HUD — Side Detector (Fixed Camera Start)</title>
<style>
  :root{--bg:#0b0f19;--accent:#0fa3ff}
  *{box-sizing:border-box}
  html,body{height:100%;margin:0;font-family:system-ui,Segoe UI,Roboto,Arial;background:var(--bg);color:#eaf4fb}
  .wrap{max-width:1100px;margin:10px auto;padding:12px}
  h1{font-size:18px;margin:0}
  .controls{display:flex;gap:8px;flex-wrap:wrap;align-items:center;margin:12px 0}
  button,select,input[type=range]{background:var(--accent);border:none;color:#012;padding:8px 12px;border-radius:10px;font-weight:700;cursor:pointer}
  button.secondary{background:#384764;color:#eaf4fb}
  .panel{background:rgba(255,255,255,0.03);padding:12px;border-radius:12px;border:1px solid rgba(255,255,255,0.04)}
  .two{display:flex;gap:12px;flex-wrap:wrap}
  .left{flex:1 1 520px;min-width:260px}
  .right{flex:0 1 320px;min-width:220px}
  .stack{position:relative;border-radius:12px;overflow:hidden;background:#fff}
  canvas#hud{width:100%;height:64vh;display:block;border-radius:8px;background:#fff}
  video#preview{position:absolute;right:12px;top:12px;width:160px;height:auto;border-radius:8px;box-shadow:0 6px 22px rgba(0,0,0,0.45);display:none}
  .status{margin-top:8px;padding:8px;border-radius:8px;background:rgba(255,255,255,0.03);font-weight:700;color:#cde3ff}
  .hint{font-size:13px;color:#ffd36b;margin-top:8px;display:none}
  .small{font-size:13px;opacity:.9}
  footer{margin-top:12px;text-align:center;color:#9fb6c9;font-size:13px}
  @media(max-width:640px){ canvas#hud{height:54vh} .two{flex-direction:column} }
</style>
</head>
<body>
  <div class="wrap">
    <h1>Top-Down HUD — Side Detector (Fixed)</h1>

    <div class="controls">
      <button id="startBtn">Start</button>
      <button id="stopBtn" class="secondary">Stop</button>
      <label style="color:#cde3ff"><input id="testMode" type="checkbox" checked> Test mode (use reference image)</label>
      <select id="camSelect" title="Camera" style="padding:8px;border-radius:8px;background:#08101a;color:#cde3ff;border:1px solid rgba(255,255,255,.04)"></select>
      <label style="margin-left:auto;color:#cde3ff">Confidence: <input id="conf" type="range" min="0.2" max="0.95" step="0.05" value="0.55" style="vertical-align:middle"/> <span id="confVal">0.55</span></label>
    </div>

    <div class="panel two">
      <div class="left">
        <div class="stack" id="stack" style="aspect-ratio:16/9;">
          <canvas id="hud"></canvas>
          <video id="preview" autoplay playsinline muted></video>
        </div>
        <div class="status" id="desc">No side objects detected.</div>
        <div class="hint" id="hint">Hint messages will appear here (permissions, HTTPS...)</div>
      </div>

      <div class="right">
        <div style="display:flex;gap:8px;flex-wrap:wrap;margin-bottom:8px">
          <button id="showLeft" class="secondary">Show Left</button>
          <button id="showRight" class="secondary">Show Right</button>
          <button id="showBoth" class="secondary">Show Both</button>
          <button id="clear" class="secondary">Clear</button>
        </div>

        <div style="font-size:13px;background:rgba(255,255,255,0.02);padding:8px;border-radius:8px">
          <div><b>Reference image (Test Mode):</b></div>
          <div style="font-family:monospace;margin-top:6px;color:#9fb6c9">/mnt/data/69126851-FAA3-40B8-BFA9-94B682CAF7D3.jpeg</div>
          <div style="margin-top:8px;font-size:12px;color:#cde3ff">Open via HTTPS or localhost to use live camera.</div>
        </div>
      </div>
    </div>

    <footer>Local detection with TensorFlow.js coco-ssd (mobilenet). No frames leave your device.</footer>
  </div>

  <!-- libs -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3"></script>

<script>
/* FIXED: robust camera start + preview + test image path
   Test image path included: /mnt/data/69126851-FAA3-40B8-BFA9-94B682CAF7D3.jpeg
*/

const TEST_IMAGE_PATH = '/mnt/data/69126851-FAA3-40B8-BFA9-94B682CAF7D3.jpeg';

const hud = document.getElementById('hud');
const preview = document.getElementById('preview');
const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const testMode  = document.getElementById('testMode');
const camSelect = document.getElementById('camSelect');
const conf = document.getElementById('conf');
const confVal = document.getElementById('confVal');
const desc = document.getElementById('desc');
const hint = document.getElementById('hint');

const showLeft = document.getElementById('showLeft');
const showRight = document.getElementById('showRight');
const showBoth = document.getElementById('showBoth');
const clearBtn = document.getElementById('clear');

const ctx = hud.getContext('2d', { willReadFrequently:true });

let model=null, stream=null, running=false, raf=null, devices=[], currentDeviceId=null;
let lastFrame=0, throttleMs = 100;

function fit(){
  const rect = document.getElementById('stack').getBoundingClientRect();
  hud.width = Math.floor(rect.width);
  hud.height = Math.floor(rect.height);
  // preview position / size
  preview.style.display = stream ? 'block' : 'none';
  preview.style.width = Math.min(160, rect.width*0.25) + 'px';
  drawBaseHUD(false,false,[],[]);
}
window.addEventListener('resize', fit);

/* Status helpers */
function setHint(t){ hint.style.display = t ? 'block' : 'none'; hint.textContent = t || ''; }
function setDesc(t){ desc.textContent = t; }
function setStatusLine(t){ /* show in hint too for simplicity */ setHint(t); }

/* load model */
async function loadModel(){
  if(model) return model;
  setStatusLine('Loading model...');
  try{
    model = await cocoSsd.load({ base: 'mobilenet_v2' });
    setStatusLine('Model ready');
    return model;
  }catch(e){
    setStatusLine('Model load failed: ' + (e.message||e));
    throw e;
  }
}

/* enumerate devices (safe even without labels) */
async function listCameras(){
  try{
    const devs = await navigator.mediaDevices.enumerateDevices();
    devices = devs.filter(d => d.kind==='videoinput');
    camSelect.innerHTML = devices.map((d,i)=>`<option value="${d.deviceId}">${d.label || 'Camera '+(i+1)}</option>`).join('');
    if(devices.length && !currentDeviceId) currentDeviceId = devices[0].deviceId;
  }catch(e){
    console.warn('enumerateDevices error', e);
  }
}

/* start camera robustly */
async function startCamera(deviceId=null){
  try{
    // warn if not https/localhost
    if(location.protocol !== 'https:' && location.hostname !== 'localhost'){
      setStatusLine('⚠️ Camera requires HTTPS or open on localhost.');
    } else setStatusLine('');

    // prefer deviceId when provided; fallback to environment facingMode
    const constraints = deviceId ? { video: { deviceId:{ exact: deviceId }, width:{ideal:1280}, height:{ideal:720} } } 
                                : { video: { facingMode:'environment', width:{ideal:1280}, height:{ideal:720} } };

    stream = await navigator.mediaDevices.getUserMedia(constraints);
    // connect stream to preview so user sees camera feed
    preview.srcObject = stream;
    preview.play().catch(()=>{});
    preview.style.display = 'block';
    // store deviceId if available from tracks
    const [t] = stream.getVideoTracks() || [];
    if(t && typeof t.getSettings === 'function'){
      const s = t.getSettings();
      if(s.deviceId) currentDeviceId = s.deviceId;
    }
    await listCameras();
    setStatusLine('Camera streaming');
    fit();
  }catch(e){
    console.error('startCamera error', e);
    // helpful messages for common errors
    if(e.name === 'NotAllowedError') setStatusLine('Permission denied — allow camera access from address bar.');
    else if(e.name === 'NotFoundError') setStatusLine('No camera found. Connect a camera or use Test Mode.');
    else setStatusLine('Camera error: ' + (e.message || e));
    throw e;
  }
}

/* stop camera */
function stopCamera(){
  if(stream) stream.getTracks().forEach(t=>t.stop());
  stream = null;
  preview.srcObject = null;
  preview.style.display = 'none';
  if(raf) cancelAnimationFrame(raf);
  running = false;
  setStatusLine('Stopped');
}

/* drawing helpers: similar to before (HUD that matches image) */
function roundRect(c,x,y,w,h,r,fill,stroke){
  if(!r) r=6;
  c.beginPath(); c.moveTo(x+r,y); c.arcTo(x+w,y,x+w,y+h,r); c.arcTo(x+w,y+h,x,y+h,r); c.arcTo(x,y+h,x,y,r); c.arcTo(x,y,x+w,y,r); c.closePath();
  if(fill) c.fill(); if(stroke) c.stroke();
}

function drawBaseHUD(left=false,right=false,leftTypes=[],rightTypes[]){
  const W = hud.width, H = hud.height;
  ctx.clearRect(0,0,W,H);
  ctx.fillStyle = '#ffffff'; ctx.fillRect(0,0,W,H);
  // road center
  const roadW = Math.min(W*0.38, 320);
  const roadX = (W - roadW)/2;
  ctx.fillStyle = '#d9d9db'; roundRect(ctx, roadX, H*0.05, roadW, H*0.9, 6, true, false);
  ctx.fillStyle = '#bfc0c2'; roundRect(ctx, roadX + roadW*0.12, H*0.18, roadW*0.76, H*0.64, 4, true, false);
  // dashed line
  ctx.strokeStyle = '#fff'; ctx.lineWidth = Math.max(2, W*0.006); ctx.setLineDash([12,14]);
  ctx.beginPath(); ctx.moveTo(W/2, H*0.18); ctx.lineTo(W/2, H*0.82); ctx.stroke(); ctx.setLineDash([]);
  // side silhouettes
  const carW = Math.min(W*0.18, 160), carH = Math.min(H*0.26, 220);
  const leftX = roadX - carW*0.8, rightX = roadX + roadW - carW*0.2, cy = H*0.58;
  drawSideSil(leftX, cy, carW, carH, left? 'rgba(120,240,160,0.15)' : 'rgba(0,0,0,0.03)');
  drawSideSil(rightX, cy, carW, carH, right? 'rgba(255,195,70,0.14)' : 'rgba(0,0,0,0.03)');
  // center car
  const cw = Math.min(W*0.18,180), ch = Math.min(H*0.26,220);
  ctx.save(); ctx.translate(W/2, H*0.54); ctx.fillStyle='#f8f8f9'; roundRect(ctx, -cw/2, -ch/2, cw, ch, 12, true, false); ctx.fillStyle='#b9bbbd'; roundRect(ctx, -cw*0.36, -ch*0.36, cw*0.72, ch*0.72, 8, true, false); ctx.restore();
  // labels
  if(left) drawLabel(leftX + 6, cy - carH*0.7, 'Side Car');
  if(right) drawLabel(rightX + 6, cy - carH*0.7, 'Side Car');
}

function drawSideSil(x,y,w,h,glow){
  if(glow && glow !== 'rgba(0,0,0,0)'){
    const g = ctx.createRadialGradient(x + w/2, y - h*0.12, Math.min(w,h)*0.08, x + w/2, y, Math.max(w,h)*0.9);
    g.addColorStop(0, glow); g.addColorStop(1, 'rgba(0,0,0,0)');
    ctx.fillStyle = g; ctx.beginPath(); ctx.ellipse(x + w/2, y, w*0.9, h*0.9, 0, 0, Math.PI*2); ctx.fill();
  }
  ctx.fillStyle = '#e9eaeb'; roundRect(ctx, x, y - h*0.5, w, h, Math.min(36, w*0.18), true, false);
}

function drawLabel(x,y,text){
  ctx.fillStyle = 'rgba(20,24,30,0.92)'; ctx.font='14px system-ui, Arial'; const pad=10;
  const tw = ctx.measureText(text).width; roundRect(ctx, x-6, y-6, tw + pad*2, 28, 10, true, false);
  ctx.fillStyle = '#fff'; ctx.fillText(text, x-6 + pad, y+12);
}

/* draw small detection boxes overlay (scaled from source to hud) */
function drawDetections(preds, thr, srcW, srcH){
  ctx.save();
  const scaleX = hud.width / srcW; const scaleY = hud.height / srcH;
  ctx.lineWidth = Math.max(2, hud.width*0.004);
  for(const p of preds){
    const [x,y,w,h] = p.bbox;
    const sx = x*scaleX, sy = y*scaleY, sw = w*scaleX, sh = h*scaleY;
    ctx.strokeStyle = p.score >= thr ? 'rgba(6,120,200,0.95)' : 'rgba(120,120,120,0.45)';
    ctx.strokeRect(sx, sy, sw, sh);
    const label = `${p.class} ${(p.score*100).toFixed(0)}%`;
    ctx.fillStyle = 'rgba(0,0,0,0.6)';
    const lw = ctx.measureText(label).width + 8;
    ctx.fillRect(sx, Math.max(0, sy - 20), lw, 18);
    ctx.fillStyle = '#fff'; ctx.fillText(label, sx + 4, Math.max(0, sy - 6));
  }
  ctx.restore();
}

/* main loop */
async function loop(now){
  if(!running) return;
  if(!model){ try{ await loadModel(); } catch(e){ setStatusLine('Model error'); raf = requestAnimationFrame(loop); return; } }
  if(now - lastFrame < throttleMs){ raf = requestAnimationFrame(loop); return; }
  lastFrame = now;

  try{
    let preds = [], srcW = 640, srcH = 480;
    if(testMode.checked){
      const img = new Image(); img.src = TEST_IMAGE_PATH; await img.decode();
      const tmp = document.createElement('canvas'); const scale = Math.min(1, 640 / img.naturalWidth);
      tmp.width = Math.floor(img.naturalWidth * scale); tmp.height = Math.floor(img.naturalHeight * scale);
      tmp.getContext('2d').drawImage(img, 0, 0, tmp.width, tmp.height);
      preds = await model.detect(tmp);
      srcW = tmp.width; srcH = tmp.height;
    } else {
      if(!preview.srcObject){ raf = requestAnimationFrame(loop); return; }
      preds = await model.detect(preview); // run on the preview video element
      // when detect on video element, width/height will be video settings
      const track = preview.srcObject.getVideoTracks()[0];
      const settings = track.getSettings();
      srcW = settings.width || preview.videoWidth || 640;
      srcH = settings.height || preview.videoHeight || 480;
    }

    const threshold = parseFloat(conf.value || 0.55);
    confVal.textContent = threshold.toFixed(2);

    const useful = preds.filter(p => ['person','car','bus','truck','bicycle','motorbike'].includes(p.class) && p.score >= 0.25);

    let leftFound=false, rightFound=false, leftTypes=[], rightTypes=[];
    for(const p of useful){
      const [x,y,w,h] = p.bbox; const cx = x + w/2; const nx = cx / srcW;
      if(nx < 0.46){ leftFound = true; leftTypes.push(p.class); }
      else if(nx > 0.54){ rightFound = true; rightTypes.push(p.class); }
      else { leftFound = true; rightFound = true; leftTypes.push(p.class); rightTypes.push(p.class); }
    }

    drawBaseHUD(leftFound, rightFound, leftTypes, rightTypes);
    drawDetections(preds, threshold, srcW, srcH);

    if(leftFound || rightFound){
      const parts = [];
      if(leftFound) parts.push('Left: ' + (leftTypes.join(',') || 'object'));
      if(rightFound) parts.push('Right: ' + (rightTypes.join(',') || 'object'));
      setDesc('Detected: ' + parts.join(' · '));
      setStatusLine('Object detected');
    } else {
      setDesc('No side objects detected.');
      setStatusLine('No side objects');
    }
  }catch(e){
    console.error('detect error', e);
    setStatusLine('Detection error: ' + (e.message || e));
  } finally {
    raf = requestAnimationFrame(loop);
  }
}

/* UI wiring + robust start */
startBtn.onclick = async ()=>{
  try{
    await listCameras(); // populate selector before starting
    // try preloading model
    loadModel().catch(()=>{});
    // if test mode off -> attempt to start camera
    if(!testMode.checked){
      // if user selected device use it; else fallback to facingMode
      const selected = camSelect.value || currentDeviceId;
      try{
        await startCamera(selected || null);
      }catch(e){
        // if deviceId failed, retry with facingMode fallback
        if(currentDeviceId && selected){
          try{ await startCamera(null); }catch(err){ throw err; }
        } else throw e;
      }
    }
    running = true;
    lastFrame = performance.now();
    raf = requestAnimationFrame(loop);
    setStatusLine('Running');
  }catch(e){
    console.error('Start error', e);
    // set hint already handled in startCamera
  }
};

stopBtn.onclick = ()=> stopCamera();

camSelect.onchange = (e)=>{ currentDeviceId = e.target.value; };

showLeft.onclick = ()=>{ drawBaseHUD(true,false); setDesc('Detected: Left (debug)'); };
showRight.onclick = ()=>{ drawBaseHUD(false,true); setDesc('Detected: Right (debug)'); };
showBoth.onclick = ()=>{ drawBaseHUD(true,true); setDesc('Detected: Both (debug)'); };
clearBtn.onclick = ()=>{ drawBaseHUD(false,false); setDesc('No side objects detected.'); };

conf.oninput = ()=> confVal.textContent = parseFloat(conf.value).toFixed(2);

/* init */
(async function init(){
  try{ await tf.ready(); console.log('TF backend:', tf.getBackend()); }catch(e){ console.warn('tf ready failed', e); }
  await listCameras();
  // preload model non-blocking
  loadModel().catch(()=>{});
  fit();
})();
</script>
</body>
</html>